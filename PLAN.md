# Stepwise DPO Project Plan

## My Understanding

This project is to re-implement a stepwise DPO method using an LLM as the evaluator, inspired by the "Let's Verify Step by Step" paper and provided baseline code.

## Checklist of Tasks

- Understand paper and repo
- Prepare dataset (prm800k or generate my own)
- Implement LLM-based stepwise reward
- Extend DPOTrainer for stepwise aggregation
- (Bonus) Run an experiment improving a small model
- Document code and experiments
- Ensure reproducibility (requirements.txt, environment.yml)
- Write comprehensive README
- Commit and push regularly to GitHub
